{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.3.1\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing legacy 'setup.py install' for pyspark, since package 'wheel' is not installed.\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Running setup.py install for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/12 21:42:20 WARN Utils: Your hostname, lucas-Estudos resolves to a loopback address: 127.0.1.1; using 192.168.0.177 instead (on interface wlp8s0)\n",
      "23/07/12 21:42:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/12 21:42:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"twitter_transformation\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"../../datalake/twitter_datascience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+------------+\n",
      "|                data|            includes|              meta|extract_date|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "|[{24, 37, 2023-07...|{[{2023-07-10T04:...|{1234567890abcdef}|  2023-07-10|\n",
      "|[{60, 37, 2023-07...|{[{2023-07-10T12:...|{1234567890abcdef}|  2023-07-10|\n",
      "|[{97, 91, 2023-07...|{[{2023-07-10T11:...|              null|  2023-07-10|\n",
      "|[{60, 17, 2023-07...|{[{2023-07-08T14:...|{1234567890abcdef}|  2023-07-08|\n",
      "|[{89, 37, 2023-07...|{[{2023-07-08T04:...|              null|  2023-07-08|\n",
      "|[{31, 44, 2023-07...|{[{2023-07-07T01:...|{1234567890abcdef}|  2023-07-07|\n",
      "|[{22, 9, 2023-07-...|{[{2023-07-07T21:...|              null|  2023-07-07|\n",
      "|[{75, 91, 2023-07...|{[{2023-07-06T19:...|{1234567890abcdef}|  2023-07-06|\n",
      "|[{61, 44, 2023-07...|{[{2023-07-06T13:...|              null|  2023-07-06|\n",
      "|[{33, 94, 2023-07...|{[{2023-07-09T01:...|              null|  2023-07-09|\n",
      "|[{24, 17, 2023-07...|{[{2023-07-11T09:...|              null|  2023-07-11|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- author_id: string (nullable = true)\n",
      " |    |-- conversation_id: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{24, 37, 2023-07-...|\n",
      "|{98, 21, 2023-07-...|\n",
      "|{95, 26, 2023-07-...|\n",
      "|{66, 71, 2023-07-...|\n",
      "|{94, 59, 2023-07-...|\n",
      "|{97, 16, 2023-07-...|\n",
      "|{88, 20, 2023-07-...|\n",
      "|{23, 92, 2023-07-...|\n",
      "|{93, 6, 2023-07-1...|\n",
      "|{91, 96, 2023-07-...|\n",
      "|{60, 37, 2023-07-...|\n",
      "|{37, 60, 2023-07-...|\n",
      "|{52, 96, 2023-07-...|\n",
      "|{37, 79, 2023-07-...|\n",
      "|{94, 76, 2023-07-...|\n",
      "|{67, 72, 2023-07-...|\n",
      "|{3, 25, 2023-07-1...|\n",
      "|{39, 49, 2023-07-...|\n",
      "|{63, 21, 2023-07-...|\n",
      "|{92, 29, 2023-07-...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- like_count: long (nullable = true)\n",
      " |-- quote_count: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\").alias(\"tweets\"))\\\n",
    ".select(\"tweets.author_id\", \"tweets.conversation_id\",\n",
    "        \"tweets.created_at\", \"tweets.id\",\n",
    "        \"tweets.public_metrics.*\", \"tweets.text\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df=df.select(f.explode(\"data\").alias(\"tweets\"))\\\n",
    ".select(\"tweets.author_id\", \"tweets.conversation_id\",\n",
    "        \"tweets.created_at\", \"tweets.id\",\n",
    "        \"tweets.public_metrics.*\", \"tweets.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|author_id|conversation_id|          created_at| id|like_count|quote_count|reply_count|retweet_count|                text|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|       24|             37|2023-07-10T15:27:...|  0|        95|          9|         58|           71|Tweet fictício ge...|\n",
      "|       98|             21|2023-07-10T01:22:...| 69|        27|         72|         49|           96|Tweet fictício ge...|\n",
      "|       95|             26|2023-07-10T06:11:...| 43|        79|         29|         54|           36|Este é um tweet f...|\n",
      "|       66|             71|2023-07-10T08:02:...| 18|        76|         82|         72|           40|Um terceiro tweet...|\n",
      "|       94|             59|2023-07-10T22:24:...| 32|        83|         53|         13|           20|Tweet fictício ge...|\n",
      "|       97|             16|2023-07-10T18:07:...| 96|        40|         33|         95|           90|Tweet fictício cr...|\n",
      "|       88|             20|2023-07-10T11:52:...| 45|        38|         42|         45|           70|Tweet fictício cr...|\n",
      "|       23|             92|2023-07-10T14:07:...| 54|        84|         22|         64|           15|Este é um tweet f...|\n",
      "|       93|              6|2023-07-10T00:39:...| 97|        74|         27|        100|           37|Um terceiro tweet...|\n",
      "|       91|             96|2023-07-10T23:31:...| 37|         7|         70|         21|           68|Outro tweet fictí...|\n",
      "|       60|             37|2023-07-10T06:48:...| 27|        69|         15|         98|           54|Tweet fictício cr...|\n",
      "|       37|             60|2023-07-10T20:22:...| 98|        89|         82|         94|           37|Um terceiro tweet...|\n",
      "|       52|             96|2023-07-10T06:01:...| 25|        70|         33|         60|           65|Tweet fictício ge...|\n",
      "|       37|             79|2023-07-10T15:49:...| 76|        33|          9|         79|            2|Tweet fictício ge...|\n",
      "|       94|             76|2023-07-10T17:44:...| 82|         8|         16|         31|           24|Outro tweet fictí...|\n",
      "|       67|             72|2023-07-10T03:36:...| 67|        65|         63|         33|           71|Um terceiro tweet...|\n",
      "|        3|             25|2023-07-10T14:16:...| 13|        92|         53|         71|            0|Um terceiro tweet...|\n",
      "|       39|             49|2023-07-10T18:24:...| 67|        84|         23|         18|           66|Tweet fictício ge...|\n",
      "|       63|             21|2023-07-10T07:10:...| 65|        72|         47|          0|           95|Um terceiro tweet...|\n",
      "|       92|             29|2023-07-10T22:15:...| 86|        56|         66|         23|           76|Tweet fictício ge...|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------+--------+\n",
      "|          created_at| id|  name|username|\n",
      "+--------------------+---+------+--------+\n",
      "|2023-07-10T04:32:...| 48|User 1|   user1|\n",
      "|2023-07-10T16:37:...| 61|User 2|   user2|\n",
      "|2023-07-10T09:00:...| 71|User 3|   user3|\n",
      "|2023-07-10T03:01:...| 98|User 4|   user4|\n",
      "|2023-07-10T09:57:...| 59|User 5|   user5|\n",
      "+--------------------+---+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df = df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\")\n",
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.coalesce(1).write.mode(\"overwrite\").json('output/tweet')\n",
    "user_df.coalesce(1).write.mode(\"overwrite\").json('output/user')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
